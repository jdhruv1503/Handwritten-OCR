{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j82QtKe1JanV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dataset"
      ],
      "metadata": {
        "id": "3buBr_RbJgIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDMgXY1dJdbQ",
        "outputId": "0661a4c5-8a81-4b67-8b16-0b75fbfc5808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "  def __init__(self, folder_path, image_size=(28, 28)):\n",
        "      self.data = []\n",
        "      self.labels = []\n",
        "      self.image_size = image_size\n",
        "      self.label_encoder = LabelEncoder()\n",
        "\n",
        "      # Get folder names as class labels and encode them\n",
        "      self.folder_names = sorted(os.listdir(folder_path))\n",
        "      self.label_encoder.fit(self.folder_names)\n",
        "\n",
        "      for label_name in self.folder_names:\n",
        "          label_folder = os.path.join(folder_path, label_name)\n",
        "          if not os.path.isdir(label_folder):\n",
        "              continue\n",
        "\n",
        "          for filename in os.listdir(label_folder):\n",
        "              img_path = os.path.join(label_folder, filename)\n",
        "              if not img_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                  continue\n",
        "\n",
        "              try:\n",
        "                  img = Image.open(img_path).convert('L')  # Convert to grayscale\n",
        "                  img = img.resize(self.image_size)\n",
        "                  img_array = np.array(img)/255.0\n",
        "                  self.data.append(img_array)\n",
        "                  self.labels.append(label_name)\n",
        "              except Exception as e:\n",
        "                  print(f\"Error loading image {img_path}: {e}\")\n",
        "\n",
        "      # Convert lists to numpy arrays and transform labels to numerical values\n",
        "      self.data = np.array(self.data)\n",
        "      self.labels = self.label_encoder.transform(self.labels)\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      image = torch.tensor(self.data[idx], dtype=torch.float32).unsqueeze(0)\n",
        "      label = torch.tensor(self.labels[idx], dtype=torch.long).unsqueeze(0)\n",
        "      return image, label\n"
      ],
      "metadata": {
        "id": "BlfF1sh2Me5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_drive(folder_path, image_size=(28, 28)):\n",
        "\n",
        "    print(f\"Loading images from {folder_path}...\")\n",
        "    data, labels = [], []\n",
        "    label_encoder = LabelEncoder()\n",
        "\n",
        "    # Get the list of folder names\n",
        "    folder_names = sorted(os.listdir(folder_path))\n",
        "    label_encoder.fit(folder_names)  # Fit the encoder with folder names as labels\n",
        "\n",
        "    for label_name in folder_names:\n",
        "        label_folder = os.path.join(folder_path, label_name)\n",
        "        if not os.path.isdir(label_folder):\n",
        "            continue\n",
        "\n",
        "        for filename in os.listdir(label_folder):\n",
        "            img_path = os.path.join(label_folder, filename)\n",
        "            if not img_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # Load and preprocess the image\n",
        "                img = Image.open(img_path).convert('L')  # Convert to grayscale\n",
        "                img = img.resize(image_size)  # Resize to the target size\n",
        "                img_array = np.array(img).flatten() / 255.0  # Flatten and normalize\n",
        "                data.append(img_array)\n",
        "                labels.append(label_name)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {img_path}: {e}\")\n",
        "\n",
        "    data = np.array(data)\n",
        "    labels = label_encoder.transform(labels)  # Encode labels as integers\n",
        "    print(f\"Loaded {len(data)} images from {len(folder_names)} classes.\")\n",
        "    return data, labels, label_encoder"
      ],
      "metadata": {
        "id": "IX2LczeaO-PL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/MyDrive/DATASET'\n",
        "dataset = None\n",
        "class_names = []\n",
        "train_dataloader, val_dataloader, label_encoder = get_dataloader(dataset, folder_path, image_size=(28, 28), batch_size=32, class_names = class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TnpLQJ_PMCM",
        "outputId": "45315540-e531-44ed-cb13-5f29a51917c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train DataLoader created with 1084 images.\n",
            "Validation DataLoader created with 271 images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_dataloader:\n",
        "  # print(images.shape)  # e.g., torch.Size([32, 784]) for batch of 32 flattened 28x28 images\n",
        "  print(labels.shape)  # e.g., torch.Size([32]) for batch of labels\n",
        "  # plt.imshow(images[0].squeeze(), cmap = 'grey')\n",
        "  # print(labels[0])\n",
        "  # break  # Only check the first batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZcQcVJtXOgD",
        "outputId": "2a6a1c8a-5552-406b-fcb7-d6d6247d82af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "torch.Size([28, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-er5YL93Jp7h",
        "outputId": "5edd7d3d-c6d1-460e-b05c-117339bae5fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'Q', 'R', 'T', 'W', 'Y', 'i', 'o', 'p', 's', 'u', 'v', 'x', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_batch, train_labels_batch = next(iter(train_dataloader)) ##iter used to access the iterable of dataloader to access batch itself\n",
        "train_features_batch.shape, train_labels_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVUtGEITJx-T",
        "outputId": "a25f0319-0075-4e24-c91f-c06dddf10add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 1, 28, 28]), torch.Size([32, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 315
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fn(y_true, y_pred):\n",
        "  correct = (y_true == y_pred).float()  # Convert boolean to float (True=1, False=0)\n",
        "  acc = correct.sum() / len(y_pred) * 100  # Percentage accuracy\n",
        "  return acc.item()"
      ],
      "metadata": {
        "id": "5Ub40g92kBx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyVGG(nn.Module):\n",
        "    \"\"\"\n",
        "    Model architecture copying TinyVGG from:\n",
        "    https://poloclub.github.io/cnn-explainer/\n",
        "    \"\"\"\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3, # how big is the square that's going over the image?\n",
        "                      stride=1, # default\n",
        "                      padding=1),# options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride=2) # default stride value is same as kernel_size\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            # Where did this in_features shape come from?\n",
        "            # It's because each layer of our network compresses and changes the shape of our input data.\n",
        "            nn.Linear(in_features=hidden_units*7*7,\n",
        "                      out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.block_2(x)\n",
        "        # print(x.shape)\n",
        "        x = self.classifier(x)\n",
        "        # print(x.shape)\n",
        "        return x\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model_2 = TinyVGG(input_shape=1,\n",
        "    hidden_units=10,\n",
        "    output_shape=len(class_names)).to(device)\n",
        "model_2"
      ],
      "metadata": {
        "id": "jijwpqqlkR1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76bdfd80-ae86-4431-8f8b-f916a2467152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyVGG(\n",
              "  (block_1): Sequential(\n",
              "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=490, out_features=26, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 317
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn,\n",
        "               device: torch.device = device):\n",
        "    loss, acc = 0, 0\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "      for X, y in data_loader:\n",
        "        # Send data to the target device\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        y_pred = model(X)\n",
        "        loss += loss_fn(y_pred.float(), y.squeeze())\n",
        "        acc += accuracy_fn(y_true=y.squeeze(), y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "      # Scale loss and acc\n",
        "      loss /= len(data_loader)\n",
        "      acc /= len(data_loader)\n",
        "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
        "            \"model_loss\": loss.item(),\n",
        "            \"model_acc\": acc}"
      ],
      "metadata": {
        "id": "GZEF-yITDvyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step1(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device: torch.device = device):\n",
        "    train_loss, train_acc = 0, 0\n",
        "    model.to(device)\n",
        "    for batch, (X, y) in enumerate(data_loader):\n",
        "      # Send data to GPU\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      # 1. Forward pass\n",
        "      y_pred = model(X)\n",
        "      # print(y_pred)\n",
        "      # print(y)\n",
        "      # 2. Calculate loss\n",
        "      loss = loss_fn(y_pred.float(), y.squeeze())\n",
        "      train_loss += loss\n",
        "      train_acc += accuracy_fn(y_true=y.squeeze(),\n",
        "                                y_pred=y_pred.argmax(dim=1)) # Go from logits -> pred labels\n",
        "\n",
        "      # 3. Optimizer zero grad\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # 4. Loss backward\n",
        "      loss.backward()\n",
        "\n",
        "      # 5. Optimizer step\n",
        "      optimizer.step()\n",
        "\n",
        "    # Calculate loss and accuracy per epoch and print out what's happening\n",
        "    train_loss /= len(data_loader)\n",
        "    train_acc /= len(data_loader)\n",
        "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
        "\n",
        "def test_step1(data_loader: torch.utils.data.DataLoader,\n",
        "              model: torch.nn.Module,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "              device: torch.device = device):\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model.to(device)\n",
        "    model.eval() # put model in eval mode\n",
        "    # Turn on inference context manager\n",
        "    with torch.inference_mode():\n",
        "      for X, y in data_loader:\n",
        "        # Send data to GPU\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        test_pred = model(X)\n",
        "\n",
        "        # 2. Calculate loss and accuracy\n",
        "        test_loss += loss_fn(test_pred.float(), y.squeeze())\n",
        "        test_acc += accuracy_fn(y_true=y.squeeze(),\n",
        "            y_pred=test_pred.argmax(dim=1) # Go from logits -> pred labels\n",
        "        )\n",
        "      # print(len(data_loader))\n",
        "      # print(test_acc)\n",
        "      # Adjust metrics and print out\n",
        "      test_loss /= len(data_loader)\n",
        "      test_acc /= len(data_loader)\n",
        "      print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
      ],
      "metadata": {
        "id": "Y5cfq4epDSnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_2.parameters(),\n",
        "                             lr=0.1)"
      ],
      "metadata": {
        "id": "Gj4eS8hyD0jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "train_features_batch.shape, train_labels_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymnWMavwEgZg",
        "outputId": "70234855-e8ca-4b0a-cd0c-9c577122034e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 1, 28, 28]), torch.Size([32, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 321
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch: {epoch}\\n---------\")\n",
        "    train_step1(data_loader=train_dataloader,\n",
        "        model=model_2,\n",
        "        loss_fn=loss_fn,\n",
        "        optimizer=optimizer,\n",
        "        accuracy_fn=accuracy_fn,\n",
        "        device=device\n",
        "    )\n",
        "    test_step1(data_loader=val_dataloader,\n",
        "        model=model_2,\n",
        "        loss_fn=loss_fn,\n",
        "        accuracy_fn=accuracy_fn,\n",
        "        device=device\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itAsK-hoB2m6",
        "outputId": "09ff74c9-a1fb-41c7-ec23-f66e817588d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "---------\n",
            "Train loss: 1.00550 | Train accuracy: 69.47%\n",
            "9\n",
            "613.1250038146973\n",
            "Test loss: 1.03670 | Test accuracy: 68.13%\n",
            "\n",
            "Epoch: 1\n",
            "---------\n",
            "Train loss: 0.61707 | Train accuracy: 82.31%\n",
            "9\n",
            "671.6666679382324\n",
            "Test loss: 0.79877 | Test accuracy: 74.63%\n",
            "\n",
            "Epoch: 2\n",
            "---------\n",
            "Train loss: 0.44840 | Train accuracy: 86.52%\n",
            "9\n",
            "695.625\n",
            "Test loss: 0.72804 | Test accuracy: 77.29%\n",
            "\n",
            "Epoch: 3\n",
            "---------\n",
            "Train loss: 0.34634 | Train accuracy: 90.24%\n",
            "9\n",
            "693.5416679382324\n",
            "Test loss: 0.88867 | Test accuracy: 77.06%\n",
            "\n",
            "Epoch: 4\n",
            "---------\n",
            "Train loss: 0.23820 | Train accuracy: 93.08%\n",
            "9\n",
            "741.2500038146973\n",
            "Test loss: 0.62175 | Test accuracy: 82.36%\n",
            "\n",
            "Epoch: 5\n",
            "---------\n",
            "Train loss: 0.13338 | Train accuracy: 96.59%\n",
            "9\n",
            "766.6666717529297\n",
            "Test loss: 0.59729 | Test accuracy: 85.19%\n",
            "\n",
            "Epoch: 6\n",
            "---------\n",
            "Train loss: 0.12203 | Train accuracy: 96.59%\n",
            "9\n",
            "743.9583358764648\n",
            "Test loss: 0.65093 | Test accuracy: 82.66%\n",
            "\n",
            "Epoch: 7\n",
            "---------\n",
            "Train loss: 0.06940 | Train accuracy: 97.98%\n",
            "9\n",
            "756.0416679382324\n",
            "Test loss: 0.70566 | Test accuracy: 84.00%\n",
            "\n",
            "Epoch: 8\n",
            "---------\n",
            "Train loss: 0.06271 | Train accuracy: 98.25%\n",
            "9\n",
            "788.1250038146973\n",
            "Test loss: 0.62205 | Test accuracy: 87.57%\n",
            "\n",
            "Epoch: 9\n",
            "---------\n",
            "Train loss: 0.02876 | Train accuracy: 99.15%\n",
            "9\n",
            "728.7500038146973\n",
            "Test loss: 1.13808 | Test accuracy: 80.97%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model 0 results on test dataset\n",
        "model_2_results = eval_model(model=model_2, data_loader=val_dataloader,\n",
        "    loss_fn=loss_fn, accuracy_fn=accuracy_fn\n",
        ")\n",
        "model_2_results"
      ],
      "metadata": {
        "id": "gNzFnHGnCcFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07be3129-f23f-4d6e-d247-7d6adca02fae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_name': 'TinyVGG',\n",
              " 'model_loss': 1.1380828619003296,\n",
              " 'model_acc': 203.44907463921442}"
            ]
          },
          "metadata": {},
          "execution_count": 329
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT8h1_1XFbNw",
        "outputId": "be730ff4-6c6f-45f1-dc94-ec305ef5e93c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 324
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "amgvL1R5LQG5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}